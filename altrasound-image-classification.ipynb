{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-26T17:23:18.943115Z","iopub.status.busy":"2023-08-26T17:23:18.942378Z","iopub.status.idle":"2023-08-26T17:23:52.443533Z","shell.execute_reply":"2023-08-26T17:23:52.442449Z","shell.execute_reply.started":"2023-08-26T17:23:18.943076Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","import random\n","\n","# Load the CSV file containing image file names and class labels\n","df = pd.read_csv('/kaggle/input/2d-fetal-altrasound-images/Classification/image_label.csv')\n","\n","# Define constants for image resizing and normalization\n","image_width = 128\n","image_height = 128\n","image_channels = 3\n","\n","# Initialize empty lists to store preprocessed data\n","images = []\n","labels = []\n","\n","# Iterate through each row in the CSV file and load/encode images and labels\n","for index, row in df.iterrows():\n","    image_path = f\"/kaggle/input/2d-fetal-altrasound-images/Classification/images/{row['Image_name']}.png\"\n","    label = row['Plane']\n","    \n","    # Load and preprocess the image\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, (image_width, image_height))\n","    image = image / 255.0  # Normalize pixel values to the range [0, 1]\n","    \n","    # Append the preprocessed image and encoded label to the lists\n","    images.append(image)\n","    labels.append(label)\n","\n","# Encode class labels into numerical values\n","label_encoder = LabelEncoder()\n","labels_encoded = label_encoder.fit_transform(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label_map = {}\n","for i, x in enumerate(labels_encoded):\n","    if x not in label_map:\n","        label_map[x] = labels[i]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:26:12.349825Z","iopub.status.busy":"2023-08-26T17:26:12.349015Z","iopub.status.idle":"2023-08-26T17:26:12.358814Z","shell.execute_reply":"2023-08-26T17:26:12.357808Z","shell.execute_reply.started":"2023-08-26T17:26:12.349782Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{1: 'Fetal brain', 2: 'Fetal femur', 3: 'Fetal thorax', 0: 'Fetal abdomen'}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["label_map"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:23:52.447879Z","iopub.status.busy":"2023-08-26T17:23:52.447022Z","iopub.status.idle":"2023-08-26T17:23:52.455063Z","shell.execute_reply":"2023-08-26T17:23:52.454103Z","shell.execute_reply.started":"2023-08-26T17:23:52.447848Z"},"trusted":true},"outputs":[],"source":["# Create an ImageDataGenerator for data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=10,  # Randomly rotate images by up to 10 degrees  # Randomly shift images vertically by up to 20% of the height\n","    shear_range=0.2,  # Shear transformations\n","    zoom_range=0.2,  # Randomly zoom in by up to 20%\n","    horizontal_flip=True,  # Randomly flip images horizontally\n","    fill_mode='nearest'  # Fill in missing pixels with the nearest value\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:24:14.939567Z","iopub.status.busy":"2023-08-26T17:24:14.938617Z","iopub.status.idle":"2023-08-26T17:24:54.358744Z","shell.execute_reply":"2023-08-26T17:24:54.357630Z","shell.execute_reply.started":"2023-08-26T17:24:14.939529Z"},"trusted":true},"outputs":[],"source":["# Augmentation\n","augmented_images = []\n","augmented_labels = []\n","\n","for i, (image, label) in enumerate(zip(images, labels_encoded)):\n","    image = np.expand_dims(image, axis=0)\n","    label = np.array([label])\n","    \n","    # Generate augmented images and labels\n","    amount = 0\n","    for batch in datagen.flow(image, label, batch_size=1):\n","        augmented_image, augmented_label = batch\n","        augmented_image = augmented_image[0]\n","        augmented_label = augmented_label[0]\n","        \n","        augmented_images.append(augmented_image)\n","        augmented_labels.append(augmented_label)\n","        \n","        amount += 1\n","        if amount >= random.choice([5,6,7,8,9,10]):  # You can adjust this number\n","            break\n","\n","# Append augmented data to the original data sets\n","images.extend(augmented_images)\n","labels_encoded = np.concatenate([labels_encoded, augmented_labels])"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:26:32.305549Z","iopub.status.busy":"2023-08-26T17:26:32.304527Z","iopub.status.idle":"2023-08-26T17:26:33.776867Z","shell.execute_reply":"2023-08-26T17:26:33.775732Z","shell.execute_reply.started":"2023-08-26T17:26:32.305508Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shape: (10236, 128, 128, 3)\n","Validation data shape: (1280, 128, 128, 3)\n","Testing data shape: (1280, 128, 128, 3)\n","Training label shape: (10236,)\n","Validation label shape: (1280,)\n","Testing label shape: (1280,)\n"]}],"source":["# Split the dataset into training, validation, and testing sets (80-10-10 split)\n","X_train, X_temp, y_train, y_temp = train_test_split(images, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","# Convert the extended data to NumPy arrays\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","X_val = np.array(X_val)\n","y_val = np.array(y_val)\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)\n","\n","# Check the shapes of the data splits\n","print(\"Training data shape:\", X_train.shape)\n","print(\"Validation data shape:\", X_val.shape)\n","print(\"Testing data shape:\", X_test.shape)\n","print(\"Training label shape:\", y_train.shape)\n","print(\"Validation label shape:\", y_val.shape)\n","print(\"Testing label shape:\", y_test.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:26:48.503378Z","iopub.status.busy":"2023-08-26T17:26:48.502991Z","iopub.status.idle":"2023-08-26T17:26:48.510570Z","shell.execute_reply":"2023-08-26T17:26:48.509361Z","shell.execute_reply.started":"2023-08-26T17:26:48.503344Z"},"trusted":true},"outputs":[],"source":["num_classes = 4\n","\n","# Convert labels to one-hot encoded format\n","y_train_onehot = to_categorical(y_train, num_classes)\n","y_val_onehot = to_categorical(y_val, num_classes)\n","y_test_onehot = to_categorical(y_test, num_classes)"]},{"cell_type":"markdown","metadata":{},"source":["## *Model Training*"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:30:55.156542Z","iopub.status.busy":"2023-08-26T17:30:55.156161Z","iopub.status.idle":"2023-08-26T17:31:47.373899Z","shell.execute_reply":"2023-08-26T17:31:47.372757Z","shell.execute_reply.started":"2023-08-26T17:30:55.156509Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","320/320 [==============================] - 17s 19ms/step - loss: 0.6405 - accuracy: 0.7683 - val_loss: 0.4729 - val_accuracy: 0.8398\n","Epoch 2/10\n","320/320 [==============================] - 4s 14ms/step - loss: 0.3058 - accuracy: 0.9003 - val_loss: 0.3427 - val_accuracy: 0.8766\n","Epoch 3/10\n","320/320 [==============================] - 4s 13ms/step - loss: 0.1634 - accuracy: 0.9448 - val_loss: 0.3101 - val_accuracy: 0.8984\n","Epoch 4/10\n","320/320 [==============================] - 4s 12ms/step - loss: 0.0842 - accuracy: 0.9725 - val_loss: 0.3140 - val_accuracy: 0.8984\n","Epoch 5/10\n","320/320 [==============================] - 4s 13ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 0.3862 - val_accuracy: 0.9062\n","Epoch 6/10\n","320/320 [==============================] - 4s 13ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.4064 - val_accuracy: 0.9016\n","40/40 [==============================] - 1s 7ms/step - loss: 0.2667 - accuracy: 0.9086\n","Test accuracy: 0.9085937738418579\n"]}],"source":["# Build a Neural Network Model\n","model = keras.Sequential([\n","    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),\n","    keras.layers.MaxPooling2D((2, 2)),\n","    keras.layers.Conv2D(16, (3, 3), activation='relu'),\n","    keras.layers.MaxPooling2D((2, 2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(128, activation='relu'),\n","    keras.layers.Dense(64, activation='relu'),\n","    keras.layers.Dense(num_classes, activation='softmax')\n","])\n","\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","early_stopping = keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=3,\n","    restore_best_weights=True\n",")\n","\n","# Train the Model\n","history = model.fit(X_train, y_train_onehot, epochs=10, validation_data=(X_val, y_val_onehot), callbacks=[early_stopping])\n","\n","# Evaluate the Model\n","test_loss, test_acc = model.evaluate(X_test, y_test_onehot)\n","print(f'Test accuracy: {test_acc}')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:31:56.176501Z","iopub.status.busy":"2023-08-26T17:31:56.173395Z","iopub.status.idle":"2023-08-26T17:31:56.337811Z","shell.execute_reply":"2023-08-26T17:31:56.336694Z","shell.execute_reply.started":"2023-08-26T17:31:56.176453Z"},"trusted":true},"outputs":[],"source":["# Save the trained model to a file\n","model.save('model.h5')"]},{"cell_type":"markdown","metadata":{},"source":["## *Inference*"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T17:52:33.017937Z","iopub.status.busy":"2023-08-26T17:52:33.017491Z","iopub.status.idle":"2023-08-26T17:52:36.029784Z","shell.execute_reply":"2023-08-26T17:52:36.028740Z","shell.execute_reply.started":"2023-08-26T17:52:33.017902Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 81ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 22ms/step\n","Predicted class: Fetal abdomen\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal abdomen\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 22ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal abdomen\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 19ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal abdomen\n","1/1 [==============================] - 0s 19ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 19ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 19ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 22ms/step\n","Predicted class: Fetal femur\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal abdomen\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 22ms/step\n","Predicted class: Fetal abdomen\n","1/1 [==============================] - 0s 22ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 22ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 19ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 19ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal abdomen\n","1/1 [==============================] - 0s 20ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 19ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal brain\n","1/1 [==============================] - 0s 24ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 21ms/step\n","Predicted class: Fetal thorax\n","1/1 [==============================] - 0s 23ms/step\n","Predicted class: Fetal femur\n"]}],"source":["# Load the saved model\n","model = keras.models.load_model('model.h5')\n","\n","images = []\n","classes = []\n","\n","# Image directory\n","dir_path = '/kaggle/input/2d-fetal-altrasound-images/Classification/External Test images'\n","\n","for file_name in os.listdir(dir_path):\n","    \n","    image_path = dir_path+\"/\"+file_name\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, (image_width, image_height))  # Resize the image to match your model's input size\n","    image = image / 255.0\n","    images.append(image)\n","    # Make a prediction on the image\n","    predictions = model.predict(np.expand_dims(image, axis=0))\n","\n","    # Decode the predictions (if you one-hot encoded your labels)\n","    predicted_class = np.argmax(predictions)\n","\n","    # Map the predicted class back to your class names\n","    predicted_class_name = label_map[predicted_class]\n","    classes.append(predicted_class_name)\n","    print(f'Predicted class: {predicted_class_name}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-08-26T18:13:40.109007Z","iopub.status.busy":"2023-08-26T18:13:40.108565Z","iopub.status.idle":"2023-08-26T18:13:40.157397Z","shell.execute_reply":"2023-08-26T18:13:40.156407Z","shell.execute_reply.started":"2023-08-26T18:13:40.108973Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# You can adjust the number of rows and columns as per your preference\n","num_rows = 8\n","num_cols = 5\n","image_spacing = 40\n","# Calculate the dimensions of the collage with spacing\n","image_height, image_width, _ = images[0].shape\n","collage_width = (image_width + image_spacing) * num_cols\n","collage_height = (image_height + image_spacing) * num_rows\n","\n","# Create an empty canvas for the collage\n","collage = np.zeros((collage_height, collage_width, 3), dtype=np.uint8)\n","\n","# Fill the canvas with new sample images and their predicted classes\n","font = cv2.FONT_HERSHEY_SIMPLEX\n","font_scale = 0.6\n","font_thickness = 2\n","font_color = (255, 255, 255)  # White text color\n","\n","for i in range(num_rows):\n","    for j in range(num_cols):\n","        index = i * num_cols + j\n","        if index < len(images):\n","            sample_image = (images[index] * 255.0).astype(np.uint8)  # Convert to 8-bit\n","            y_offset = i * (image_height + image_spacing)\n","            x_offset = j * (image_width + image_spacing)\n","            collage[y_offset:y_offset + image_height, x_offset:x_offset + image_width] = sample_image\n","\n","            # Add the predicted class label\n","            class_label = classes[index]\n","            text_size, _ = cv2.getTextSize(class_label, font, font_scale, font_thickness)\n","            text_x = x_offset + (sample_image.shape[1] - text_size[0]) // 2\n","            text_y = y_offset + sample_image.shape[0] + text_size[1] + 5\n","            cv2.putText(collage, class_label, (text_x, text_y), font, font_scale, font_color, font_thickness)\n","\n","cv2.imwrite('Image_with_Prediction.jpg', collage)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
